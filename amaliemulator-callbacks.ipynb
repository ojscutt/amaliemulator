{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea59cbfc-2068-4871-909a-00d34c580cae",
   "metadata": {},
   "source": [
    "# amaliemulator-callbacks\n",
    "adding some callbacks for tensorboard logging and checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66e344be-c24c-4502-8f1e-b6fa34b056de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-01 11:44:53.083798: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-01 11:44:53.083829: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-01 11:44:53.084798: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-01 11:44:53.089886: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-01 11:44:53.643182: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current GPU usage:\n",
      " - GPU0: 0B\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-01 11:44:54.145030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 18226 MB memory:  -> device: 0, name: NVIDIA RTX A4500, pci bus id: 0000:41:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "#### misc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import time\n",
    "from itertools import product\n",
    "\n",
    "#### graphical\n",
    "import matplotlib.pyplot as plt\n",
    "import corner\n",
    "\n",
    "#### ML\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "##### poke gpu\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\") \n",
    "\n",
    "gpu0usage = tf.config.experimental.get_memory_info(\"GPU:0\")[\"current\"]\n",
    "\n",
    "print(\"Current GPU usage:\\n\"\n",
    "     + \" - GPU0: \" + str(gpu0usage) + \"B\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9903b58f-e2c8-4fe0-bb34-441730d1ec7a",
   "metadata": {},
   "source": [
    "## data prep\n",
    "usually called 'data augmentation' in the ML community, but I think referees will have questions if you say \"we augmented the data to make our network train better\" - this is where we get our data ready for a neural network to start training.\\\n",
    "usually consists of:\n",
    "- check and clean data to remove NaNs etc\n",
    "- define our inputs and outputs for training\n",
    "- scale data for better network training\n",
    "- split into our *train*, *validation*, and *test* sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8707c78-ed3f-444f-a1d7-74e3ebb2caa9",
   "metadata": {},
   "source": [
    "### inps, outs and normalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62cdc759-1494-4a5b-b9ff-4227989596b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial_mass</th>\n",
       "      <th>initial_Zinit</th>\n",
       "      <th>initial_Yinit</th>\n",
       "      <th>initial_MLT</th>\n",
       "      <th>star_age</th>\n",
       "      <th>radius</th>\n",
       "      <th>luminosity</th>\n",
       "      <th>surface_Z</th>\n",
       "      <th>nu_0_16</th>\n",
       "      <th>nu_0_17</th>\n",
       "      <th>nu_0_18</th>\n",
       "      <th>nu_0_19</th>\n",
       "      <th>nu_0_20</th>\n",
       "      <th>nu_0_21</th>\n",
       "      <th>nu_0_22</th>\n",
       "      <th>nu_0_23</th>\n",
       "      <th>nu_0_24</th>\n",
       "      <th>nu_0_25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.160882e+06</td>\n",
       "      <td>1.160882e+06</td>\n",
       "      <td>1.160882e+06</td>\n",
       "      <td>1.160882e+06</td>\n",
       "      <td>1.160882e+06</td>\n",
       "      <td>1.160882e+06</td>\n",
       "      <td>1.160882e+06</td>\n",
       "      <td>1.160882e+06</td>\n",
       "      <td>1.160882e+06</td>\n",
       "      <td>1.160882e+06</td>\n",
       "      <td>1.160882e+06</td>\n",
       "      <td>1.160882e+06</td>\n",
       "      <td>1.160882e+06</td>\n",
       "      <td>1.160882e+06</td>\n",
       "      <td>1.160882e+06</td>\n",
       "      <td>1.160882e+06</td>\n",
       "      <td>1.160882e+06</td>\n",
       "      <td>1.160882e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.368254e-01</td>\n",
       "      <td>2.946521e-01</td>\n",
       "      <td>4.784779e-01</td>\n",
       "      <td>5.010575e-01</td>\n",
       "      <td>3.297499e-01</td>\n",
       "      <td>3.507220e-01</td>\n",
       "      <td>1.021305e-01</td>\n",
       "      <td>2.687424e-01</td>\n",
       "      <td>3.811411e-01</td>\n",
       "      <td>3.809857e-01</td>\n",
       "      <td>3.811407e-01</td>\n",
       "      <td>3.813563e-01</td>\n",
       "      <td>3.816525e-01</td>\n",
       "      <td>3.819317e-01</td>\n",
       "      <td>3.821951e-01</td>\n",
       "      <td>3.824622e-01</td>\n",
       "      <td>3.827019e-01</td>\n",
       "      <td>3.829539e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.377429e-01</td>\n",
       "      <td>2.666994e-01</td>\n",
       "      <td>2.869593e-01</td>\n",
       "      <td>2.884864e-01</td>\n",
       "      <td>2.497901e-01</td>\n",
       "      <td>1.698813e-01</td>\n",
       "      <td>8.955022e-02</td>\n",
       "      <td>2.483849e-01</td>\n",
       "      <td>1.693456e-01</td>\n",
       "      <td>1.692041e-01</td>\n",
       "      <td>1.690380e-01</td>\n",
       "      <td>1.688894e-01</td>\n",
       "      <td>1.687943e-01</td>\n",
       "      <td>1.687081e-01</td>\n",
       "      <td>1.686277e-01</td>\n",
       "      <td>1.685631e-01</td>\n",
       "      <td>1.685077e-01</td>\n",
       "      <td>1.684881e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.660000e-01</td>\n",
       "      <td>6.466661e-02</td>\n",
       "      <td>2.287215e-01</td>\n",
       "      <td>2.515570e-01</td>\n",
       "      <td>1.272709e-01</td>\n",
       "      <td>2.308146e-01</td>\n",
       "      <td>3.860117e-02</td>\n",
       "      <td>5.064833e-02</td>\n",
       "      <td>2.581992e-01</td>\n",
       "      <td>2.582190e-01</td>\n",
       "      <td>2.586089e-01</td>\n",
       "      <td>2.590295e-01</td>\n",
       "      <td>2.594966e-01</td>\n",
       "      <td>2.599090e-01</td>\n",
       "      <td>2.602957e-01</td>\n",
       "      <td>2.607057e-01</td>\n",
       "      <td>2.610569e-01</td>\n",
       "      <td>2.613862e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.700000e-01</td>\n",
       "      <td>2.100469e-01</td>\n",
       "      <td>4.667237e-01</td>\n",
       "      <td>5.003053e-01</td>\n",
       "      <td>2.730798e-01</td>\n",
       "      <td>3.216508e-01</td>\n",
       "      <td>7.600686e-02</td>\n",
       "      <td>1.953707e-01</td>\n",
       "      <td>3.768755e-01</td>\n",
       "      <td>3.767587e-01</td>\n",
       "      <td>3.769879e-01</td>\n",
       "      <td>3.773078e-01</td>\n",
       "      <td>3.776838e-01</td>\n",
       "      <td>3.780518e-01</td>\n",
       "      <td>3.784121e-01</td>\n",
       "      <td>3.787779e-01</td>\n",
       "      <td>3.791128e-01</td>\n",
       "      <td>3.794663e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.320000e-01</td>\n",
       "      <td>4.770009e-01</td>\n",
       "      <td>7.226768e-01</td>\n",
       "      <td>7.512517e-01</td>\n",
       "      <td>4.900688e-01</td>\n",
       "      <td>4.376292e-01</td>\n",
       "      <td>1.377703e-01</td>\n",
       "      <td>4.415408e-01</td>\n",
       "      <td>4.987978e-01</td>\n",
       "      <td>4.984398e-01</td>\n",
       "      <td>4.983696e-01</td>\n",
       "      <td>4.984007e-01</td>\n",
       "      <td>4.985765e-01</td>\n",
       "      <td>4.987463e-01</td>\n",
       "      <td>4.989045e-01</td>\n",
       "      <td>4.990806e-01</td>\n",
       "      <td>4.992358e-01</td>\n",
       "      <td>4.994514e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       initial_mass  initial_Zinit  initial_Yinit   initial_MLT      star_age  \\\n",
       "count  1.160882e+06   1.160882e+06   1.160882e+06  1.160882e+06  1.160882e+06   \n",
       "mean   6.368254e-01   2.946521e-01   4.784779e-01  5.010575e-01  3.297499e-01   \n",
       "std    2.377429e-01   2.666994e-01   2.869593e-01  2.884864e-01  2.497901e-01   \n",
       "min    0.000000e+00   0.000000e+00   0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    4.660000e-01   6.466661e-02   2.287215e-01  2.515570e-01  1.272709e-01   \n",
       "50%    6.700000e-01   2.100469e-01   4.667237e-01  5.003053e-01  2.730798e-01   \n",
       "75%    8.320000e-01   4.770009e-01   7.226768e-01  7.512517e-01  4.900688e-01   \n",
       "max    1.000000e+00   1.000000e+00   1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "             radius    luminosity     surface_Z       nu_0_16       nu_0_17  \\\n",
       "count  1.160882e+06  1.160882e+06  1.160882e+06  1.160882e+06  1.160882e+06   \n",
       "mean   3.507220e-01  1.021305e-01  2.687424e-01  3.811411e-01  3.809857e-01   \n",
       "std    1.698813e-01  8.955022e-02  2.483849e-01  1.693456e-01  1.692041e-01   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    2.308146e-01  3.860117e-02  5.064833e-02  2.581992e-01  2.582190e-01   \n",
       "50%    3.216508e-01  7.600686e-02  1.953707e-01  3.768755e-01  3.767587e-01   \n",
       "75%    4.376292e-01  1.377703e-01  4.415408e-01  4.987978e-01  4.984398e-01   \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "            nu_0_18       nu_0_19       nu_0_20       nu_0_21       nu_0_22  \\\n",
       "count  1.160882e+06  1.160882e+06  1.160882e+06  1.160882e+06  1.160882e+06   \n",
       "mean   3.811407e-01  3.813563e-01  3.816525e-01  3.819317e-01  3.821951e-01   \n",
       "std    1.690380e-01  1.688894e-01  1.687943e-01  1.687081e-01  1.686277e-01   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    2.586089e-01  2.590295e-01  2.594966e-01  2.599090e-01  2.602957e-01   \n",
       "50%    3.769879e-01  3.773078e-01  3.776838e-01  3.780518e-01  3.784121e-01   \n",
       "75%    4.983696e-01  4.984007e-01  4.985765e-01  4.987463e-01  4.989045e-01   \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "            nu_0_23       nu_0_24       nu_0_25  \n",
       "count  1.160882e+06  1.160882e+06  1.160882e+06  \n",
       "mean   3.824622e-01  3.827019e-01  3.829539e-01  \n",
       "std    1.685631e-01  1.685077e-01  1.684881e-01  \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "25%    2.607057e-01  2.610569e-01  2.613862e-01  \n",
       "50%    3.787779e-01  3.791128e-01  3.794663e-01  \n",
       "75%    4.990806e-01  4.992358e-01  4.994514e-01  \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = pd.read_hdf('/home/oxs235/datastorage/repos_data/ojscutt/pitchfork/data/barbie_nu.h5', key='df') ## edit for your grid!!\n",
    "\n",
    "#### define inputs\n",
    "inputs = ['initial_mass', 'initial_Zinit', 'initial_Yinit', 'initial_MLT', 'star_age']\n",
    "\n",
    "#### define outputs\n",
    "classical_outputs = ['radius', 'luminosity', 'surface_Z']\n",
    "astero_outputs = [f'nu_0_{i+1}' for i in range(15,25)] # 10 modes for now\n",
    "\n",
    "outputs = classical_outputs+astero_outputs\n",
    "\n",
    "df = df_full[inputs+outputs]\n",
    "\n",
    "df_norm = (df - df.min())/(df.max() - df.min())\n",
    "\n",
    "## check df_norm.describe looks reasonable (min=0, max=1):\n",
    "df_norm.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf18bde-5e67-44b3-ae19-94b9edcf570d",
   "metadata": {},
   "source": [
    "### split into train/validate/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53cae678-f6f8-4a53-9876-ae934d8ecef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:  1047696\n",
      "Validation set:  55142\n",
      "Test set:  58044\n"
     ]
    }
   ],
   "source": [
    "#### train/test split with seed \n",
    "seed = 42\n",
    "\n",
    "df_train = df_norm.sample(frac=0.95, random_state=seed)\n",
    "df_test = df_norm.drop(df_train.index)\n",
    "\n",
    "df_train_inputs, df_val_inputs, df_train_outputs, df_val_outputs = sklearn.model_selection.train_test_split(df_train[inputs],df_train[outputs], test_size = 0.05, random_state=seed)\n",
    "\n",
    "print(\"Training set: \", len(df_train_inputs))\n",
    "print(\"Validation set: \", len(df_val_inputs))\n",
    "print(\"Test set: \", len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0e581b-e8b1-4d5d-ac21-df18cef213dd",
   "metadata": {},
   "source": [
    "## training our network\n",
    "here we'll use our *train* and *validation* sets to train our neural network and check for overfitting\\\n",
    "I'm using the tensorflow functional API here - while this is a little harder to understand than the sequential API, it's more versatile and will let us do fun things like branching the neural network architecture later on!\\\n",
    "This time I've dropped in my 'pitchfork' branching neural network architecture. Let me know if you need any explainations for this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ee02cd-9214-426a-9b8b-ac5fae95fe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "        ________\n",
    "_______/\n",
    "       \\________\n",
    "| stem | tines |\n",
    "\n",
    "\"\"\"\n",
    "######## define architecture:\n",
    "model_name = 'pitchfork'\n",
    "\n",
    "stem_dense_layers = 2 #number of dense layers in stem\n",
    "stem_dense_units = 128 #neurons per dense layer in stem\n",
    "\n",
    "ctine_dense_layers = 2 #number of dense layers in 'classicals' tine\n",
    "ctine_dense_units = 64 #neurons per dense layer in 'classicals' tine\n",
    "\n",
    "atine_dense_layers = 6 #number of dense layers in 'asteroseismic' tine\n",
    "atine_dense_units = 128 #neurons per dense layer in 'asteroseismic' tine\n",
    "\n",
    "\n",
    "######## stem\n",
    "#### input\n",
    "stem_input = keras.Input(shape=(len(inputs),))\n",
    "\n",
    "for stem_dense_layer in range(stem_dense_layers):\n",
    "    if stem_dense_layer == 0:\n",
    "        stem = layers.Dense(stem_dense_units, activation='elu')(stem_input)\n",
    "    else:\n",
    "        stem = layers.Dense(stem_dense_units, activation='elu')(stem)\n",
    "\n",
    "######## classical tine\n",
    "#### dense layers\n",
    "for ctine_dense_layer in range(ctine_dense_layers):\n",
    "    if ctine_dense_layer == 0:\n",
    "        ctine = layers.Dense(ctine_dense_units, activation='elu')(stem)\n",
    "    else:\n",
    "        ctine = layers.Dense(ctine_dense_units, activation='elu')(ctine)\n",
    "\n",
    "#### output\n",
    "ctine_out = layers.Dense(len(classical_outputs),name='classical_outs')(ctine)\n",
    "\n",
    "\n",
    "######## astero tine\n",
    "#### dense layers\n",
    "for atine_dense_layer in range(atine_dense_layers):\n",
    "    if atine_dense_layer == 0:\n",
    "        atine = layers.Dense(atine_dense_units, activation='elu')(stem)\n",
    "    else:\n",
    "        atine = layers.Dense(atine_dense_units, activation='elu')(atine)\n",
    "\n",
    "#### output\n",
    "atine_out = layers.Dense(int(len(astero_outputs)))(atine)\n",
    "\n",
    "######## construct and fit\n",
    "model = keras.Model(inputs=stem_input, outputs=[ctine_out, atine_out], name='tuning_fork')\n",
    "\n",
    "######## plot model\n",
    "keras.utils.plot_model(model, \"figs/\"+model_name+\".png\", show_layer_activations=True, show_shapes=True, show_layer_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafd160d-d8af-4e8e-b920-09a1eb2cfa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## compile and start training\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    \n",
    "model.compile(loss='MSE', optimizer=optimizer)\n",
    "\n",
    "#### fit model\n",
    "## learning rate scheduler, decreases learning rate in-training for stability\n",
    "def scheduler(epoch, lr):\n",
    "    if lr < 1e-5:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.00006)\n",
    "\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=0)\n",
    "\n",
    "## tensorboard logging callback, to avoid having to rely on tensorflow readout\n",
    "\n",
    "log_dir = f\"/home/oxs235/datastorage/repos_data/ojscutt/amaliemulator/logs/fit/{model_name}\"#<-- enter your log directory here! \n",
    "\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir) \n",
    "\n",
    "#to use tensorboard:\n",
    "# 1) open console in parent directory containing logs file (for above it'd be /home/oxs235/datastorage/repos_data/ojscutt/amaliemulator/)\n",
    "# 2) run `tensorboard --logdir logs/fit --port=8874', set port to any open port not currently in use by jupyter\n",
    "# 3) paste returned url into browser (for above it'd be `http://localhost:8874/')\n",
    "\n",
    "# saving logs from different models in the same directory (e.g. logs/fit) under different model names means we can compare in one instance of tensorboard!\n",
    "\n",
    "## checkpointing callback, to save copy of model during training at detected minima in validation loss\n",
    "\n",
    "model_dir = f\"/home/oxs235/datastorage/repos_data/ojscutt/amaliemulator/models/\"#<-- enter your models directory here! \n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(model_dir+model_name+\"_checkpoint.h5\", #define model name and directory\n",
    "                                                 monitor= 'val_loss', #value to monitor\n",
    "                                                 save_best_only= True, #overwrite worse models to avoid memory consumption\n",
    "                                                 save_freq='epoch') #check val_loss every epoch\n",
    "\n",
    "\n",
    "history = model.fit(df_train_inputs,\n",
    "                    [df_train_outputs[classical_outputs],df_train_outputs[astero_outputs]],\n",
    "                    validation_data=(df_val_inputs,[df_val_outputs[classical_outputs], df_val_outputs[astero_outputs]]),\n",
    "                    batch_size=32768,\n",
    "                    verbose=1,\n",
    "                    epochs=100000,\n",
    "                    callbacks=[lr_callback, tb_callback, cp_callback],\n",
    "                    shuffle=True\n",
    "                   ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcdcbac-bada-4856-a2a5-c842c514b19a",
   "metadata": {},
   "source": [
    "## testing the network\n",
    "this section is very rushed, the main thing is to remember to rescale your data (as the network will predict in the normalised space), and to predict on the test set that was taken out of the dataset before training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3afa699-0ac0-4908-89dd-435f39d9b558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnorm(df_norm, df_min, df_max):\n",
    "    df_unnorm = (df_norm*(df_max-df_min)) + df_min\n",
    "    return df_unnorm\n",
    "\n",
    "preds_norm = model(np.array(df_test[inputs]))\n",
    "\n",
    "df_preds_norm = pd.DataFrame(preds, columns=outputs)\n",
    "df_preds_unnorm = unnorm(preds_df_norm, df[outputs].min(), df[outputs].max())\n",
    "\n",
    "df_test_unnorm = unnorm(df_test, df.min(), df.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f713e64a-2e5a-4425-900b-68bee7923258",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = corner.corner(df_test_unnorm[outputs])\n",
    "corner.corner(df_preds_unnorm, color='red', fig=figure);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b8f7da-bb48-4905-a6ad-88083c176f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
